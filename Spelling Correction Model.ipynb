{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtp9SSIgmFO7oUXZsR0fWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogeeshsm/Tensorflow_projects/blob/main/Spelling%20Correction%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYDYL-7GZYbP",
        "outputId": "b6c8bf33-137c-4138-df52-d03b0e33c87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machin → machine\n",
            "lerning → learning\n",
            "deeep → deep\n",
            "corected → corrected\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import collections\n",
        "\n",
        "# Sample corpus text to build word frequency (can be replaced with large corpus)\n",
        "corpus = \"\"\"\n",
        "machine learning is fun and powerful. machine learning algorithms are used everywhere.\n",
        "deep learning is a subset of machine learning. spelling mistakes can be corrected.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize words\n",
        "def words(text):\n",
        "    return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "# Build frequency dictionary\n",
        "word_counts = collections.Counter(words(corpus))\n",
        "word_probs = {w: count / sum(word_counts.values()) for w, count in word_counts.items()}\n",
        "\n",
        "# Vocabulary\n",
        "WORDS = set(word_counts)\n",
        "\n",
        "# Generate possible edits (1 edit distance away)\n",
        "def edits1(word):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes = [L + R[1:] for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "    inserts = [L + c + R for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "# Known words from candidates\n",
        "def known(words):\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "# Generate candidates and rank by probability\n",
        "def correct(word):\n",
        "    candidates = (known([word]) or\n",
        "                  known(edits1(word)) or\n",
        "                  [word])\n",
        "    return max(candidates, key=lambda w: word_probs.get(w, 0))\n",
        "\n",
        "# Test the model\n",
        "misspelled = [\"machin\", \"lerning\", \"deeep\", \"corected\"]\n",
        "for w in misspelled:\n",
        "    print(f\"{w} → {correct(w)}\")\n"
      ]
    }
  ]
}